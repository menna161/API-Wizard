import dill
import os
import sys
from quantile_ml import utils_categorical_ensembling
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier
from sklearn.linear_model import RandomizedLasso, RandomizedLogisticRegression, RANSACRegressor, LinearRegression, Ridge, Lasso, ElasticNet, LassoLars, OrthogonalMatchingPursuit, BayesianRidge, ARDRegression, SGDRegressor, PassiveAggressiveRegressor, LogisticRegression, RidgeClassifier, SGDClassifier, Perceptron, PassiveAggressiveClassifier
from sklearn.cluster import MiniBatchKMeans
from quantile_ml import utils
from xgboost import XGBClassifier, XGBRegressor
from lightgbm import LGBMRegressor, LGBMClassifier
from tensorflow import logging
from keras.constraints import maxnorm
from keras.layers import Dense, Dropout
from keras.layers.advanced_activations import LeakyReLU, PReLU
from keras.models import Sequential
from keras.models import load_model as keras_load_model
from keras import regularizers
from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier


def get_search_params(model_name):
    grid_search_params = {'DeepLearningRegressor': {'hidden_layers': [[1], [1, 0.1], [1, 1, 1], [1, 0.5, 0.1], [2], [5], [1, 0.5, 0.25, 0.1, 0.05], [1, 1, 1, 1], [1, 1]]}, 'DeepLearningClassifier': {'hidden_layers': [[1], [0.5], [2], [1, 1], [0.5, 0.5], [2, 2], [1, 1, 1], [1, 0.5, 0.5], [0.5, 1, 1], [1, 0.5, 0.25], [1, 2, 1], [1, 1, 1, 1], [1, 0.66, 0.33, 0.1], [1, 2, 2, 1]], 'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'], 'dropout_rate': [0.0, 0.3, 0.6, 0.8, 0.9]}, 'XGBClassifier': {'max_depth': [1, 5, 10, 15], 'learning_rate': [0.1], 'min_child_weight': [1, 5, 10, 50], 'subsample': [0.5, 0.8, 1.0], 'colsample_bytree': [0.5, 0.8, 1.0]}, 'XGBRegressor': {'max_depth': [1, 3, 8, 25], 'subsample': [0.5, 1.0]}, 'GradientBoostingRegressor': {'max_depth': [1, 2, 3, 5], 'max_features': ['sqrt', 'log2', None], 'loss': ['ls', 'huber'], 'subsample': [0.5, 0.8, 1.0]}, 'GradientBoostingClassifier': {'loss': ['deviance', 'exponential'], 'max_depth': [1, 2, 3, 5], 'max_features': ['sqrt', 'log2', None], 'subsample': [0.5, 1.0]}, 'LogisticRegression': {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'class_weight': [None, 'balanced'], 'solver': ['newton-cg', 'lbfgs', 'sag']}, 'LinearRegression': {'fit_intercept': [True, False], 'normalize': [True, False]}, 'RandomForestClassifier': {'criterion': ['entropy', 'gini'], 'class_weight': [None, 'balanced'], 'max_features': ['sqrt', 'log2', None], 'min_samples_split': [1, 2, 5, 20, 50, 100], 'min_samples_leaf': [1, 2, 5, 20, 50, 100], 'bootstrap': [True, False]}, 'RandomForestRegressor': {'max_features': ['auto', 'sqrt', 'log2', None], 'min_samples_split': [1, 2, 5, 20, 50, 100], 'min_samples_leaf': [1, 2, 5, 20, 50, 100], 'bootstrap': [True, False]}, 'RidgeClassifier': {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'class_weight': [None, 'balanced'], 'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag']}, 'Ridge': {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag']}, 'ExtraTreesRegressor': {'max_features': ['auto', 'sqrt', 'log2', None], 'min_samples_split': [1, 2, 5, 20, 50, 100], 'min_samples_leaf': [1, 2, 5, 20, 50, 100], 'bootstrap': [True, False]}, 'AdaBoostRegressor': {'base_estimator': [None, LinearRegression(n_jobs=(- 1))], 'loss': ['linear', 'square', 'exponential']}, 'RANSACRegressor': {'min_samples': [None, 0.1, 100, 1000, 10000], 'stop_probability': [0.99, 0.98, 0.95, 0.9]}, 'Lasso': {'selection': ['cyclic', 'random'], 'tol': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'positive': [True, False]}, 'ElasticNet': {'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9], 'selection': ['cyclic', 'random'], 'tol': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'positive': [True, False]}, 'LassoLars': {'positive': [True, False], 'max_iter': [50, 100, 250, 500, 1000]}, 'OrthogonalMatchingPursuit': {'n_nonzero_coefs': [None, 3, 5, 10, 25, 50, 75, 100, 200, 500]}, 'BayesianRidge': {'tol': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'alpha_1': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'lambda_1': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'lambda_2': [1e-07, 1e-06, 1e-05, 0.0001, 0.001]}, 'ARDRegression': {'tol': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'alpha_1': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'alpha_2': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'lambda_1': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'lambda_2': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'threshold_lambda': [100, 1000, 10000, 100000, 1000000]}, 'SGDRegressor': {'loss': ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['none', 'l2', 'l1', 'elasticnet'], 'learning_rate': ['constant', 'optimal', 'invscaling'], 'alpha': [1e-07, 1e-06, 1e-05, 0.0001, 0.001]}, 'PassiveAggressiveRegressor': {'epsilon': [0.01, 0.05, 0.1, 0.2, 0.5], 'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'], 'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]}, 'SGDClassifier': {'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['none', 'l2', 'l1', 'elasticnet'], 'alpha': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'learning_rate': ['constant', 'optimal', 'invscaling'], 'class_weight': ['balanced', None]}, 'Perceptron': {'penalty': ['none', 'l2', 'l1', 'elasticnet'], 'alpha': [1e-07, 1e-06, 1e-05, 0.0001, 0.001], 'class_weight': ['balanced', None]}, 'PassiveAggressiveClassifier': {'loss': ['hinge', 'squared_hinge'], 'class_weight': ['balanced', None], 'C': [0.01, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95, 0.99, 1.0]}, 'LGBMClassifier': {'num_leaves': [10, 20, 30, 40, 50, 200], 'colsample_bytree': [0.7, 0.9, 1.0], 'subsample': [0.7, 0.9, 1.0], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [5, 20, 50, 200]}, 'LGBMRegressor': {'num_leaves': [10, 20, 30, 40, 50, 200], 'colsample_bytree': [0.7, 0.9, 1.0], 'subsample': [0.7, 0.9, 1.0], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [5, 20, 50, 200]}}
    params = grid_search_params[model_name]
    if (os.environ.get('is_test_suite', 0) == 'True'):
        simplified_params = {}
        for (k, v) in params.items():
            simplified_params[k] = v[:2]
        params = simplified_params
    return params
