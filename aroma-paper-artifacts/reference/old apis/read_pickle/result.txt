INFO:root:Namespace(corpus='read_pickle/snippets.json', working_dir='read_pickle/tmpout', file_query=[], keywords=[], index_query=None, testall=False)
INFO:root:Dumped vocab with size 285
INFO:root:Done featurizing.
INFO:root:Done computing counter matrix.
INFO:root:Read all records.
python3 src/main/python/similar.py -c read_pickle/snippets.json -d   1.97s user 1.75s system 373% cpu 0.995 total
INFO:root:Namespace(corpus=None, working_dir='read_pickle/tmpout', file_query=['read_pickle/test.json'], keywords=[], index_query=None, testall=False)
INFO:root:Loaded vocab with size 285
INFO:root:Read all records.
Query features: 
rd ##1>rd #1>rd pd ##1>pd =#2>pd ##2>pd rd>>pd rd>>pd read_pickle #UNK ##2>read_pickle =#2>read_pickle pd>>read_pickle pd>>read_pickle
INFO:root:# of similar snippets = 5
Failed to match original method.
INFO:root:Pruning 2 [0, 1]
Pruning 2 [0, 1]
INFO:root:recommending
INFO:root:Pruning 3 [2, 3, 4]
Pruning 3 [2, 3, 4]
INFO:root:recommending
INFO:root:Pruning 2 [2, 3]
INFO:root:Pruning 2 [3, 4]
################ query code ################ index = -1
rd = pd.read_pickle()


------------------- suggested code examples ------------------

------------------------- example 1 ------------------------
first_part = clean_name[:-14]
if first_part == first_part2:
    rd = pd.read_pickle('./test/'+file2)
    frame_dfs_names.append(file2)
    annotation = pd.read_pickle('./test/'+file)
    annots_dfs.append(annotation)


------------------------- example 2 ------------------------
def get_pctd(date, count=1):
    df = pd.read_pickle('../data/factors/pctd'+str(count)+'.pkl')
    return df.loc[date].sort_values().index.tolist()


def get_pctd60_rank(date):
    rd = pd.read_pickle('../data/factors/pctd60_rank.pkl')


idx = 0:------------------- similar code ------------------ index = 5, score = 12.0
first_part = clean_name[:-14]
if first_part == first_part2:
    rd = pd.read_pickle('./test/'+file2)
    frame_dfs_names.append(file2)
    annotation = pd.read_pickle('./test/'+file)
    annots_dfs.append(annotation)


------------------- similar code (pruned) ------------------ score = 0.8235294117647058
if:
    rd = pd.read_pickle


idx = 1:------------------- similar code ------------------ index = 1, score = 12.0
first_part2 = clean_name2[:-14]
if first_part == first_part2:
    rd = pd.read_pickle('./test/'+file2)
    frame_dfs_names.append(file2)
    rd = pd.read_pickle('./test/'+file)
    annots_dfs.append(annotation)


------------------- similar code (pruned) ------------------ score = 0.8235294117647058
if:
    rd = pd.read_pickle


idx = 2:------------------- similar code ------------------ index = 4, score = 12.0
def get_pctd(date, count=1):
    df = pd.read_pickle('../data/factors/pctd'+str(count)+'.pkl')
    return df.loc[date].sort_values().index.tolist()


def get_pctd60_rank(date):
    rd = pd.read_pickle('../data/factors/pctd60_rank.pkl')


------------------- similar code (pruned) ------------------ score = 0.7222222222222222
def  ... ():
     ...  =  ... .read_pickle
def  ... ( ... ):
    rd = pd


idx = 3:------------------- similar code ------------------ index = 3, score = 12.0
import numpy as np
raw_data = pd.read_pickle('raw_data')
# size = pd.read_pickle('size')  #시가총액
rd = pd.read_pickle('ni')
rd = pd.read_pickle('rtn')
rd = pd.read_pickle('equity')
rd = pd.read_pickle('operate')
rd = pd.read_pickle('kospi')


------------------- similar code (pruned) ------------------ score = 0.7222222222222222
 ...  =  ... .read_pickle
# size = pd.read_pickle('size')  #시가총액
rd = pd


idx = 4:------------------- similar code ------------------ index = 2, score = 12.0
lai_iir = pd.read_pickle('Data/Nebraska/LAI_2000_2018_Nebraska.PData')
rd = pd.read_pickle('Data/Nebraska/LAI_C4_2000_2018_Nebraska.PData')
corn_y = pd.read_csv('Data/Nebraska/NE_Corn_Production_2000_2018_bu-acre.csv')


------------------- similar code (pruned) ------------------ score = 0.7222222222222222
 ...  =  ... .read_pickle
rd = pd



python3 src/main/python/similar.py -d read_pickle/tmpout -f   1.27s user 1.66s system 383% cpu 0.763 total